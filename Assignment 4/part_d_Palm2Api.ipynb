{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanasree-Rajamani/SpecialTopics_DeepLearning/blob/main/Assignment%204/part_d_Palm2Api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this assignment, I have used Palm2 Api to implement the OpenAI example applications\n",
        "\n",
        "I have also followed the best practices of prompt Engineering"
      ],
      "metadata": {
        "id": "tJibojJeHVz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ7msHTBOhMm",
        "outputId": "b855fe93-2151-43cc-b8f6-52c9afc81063"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/77.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grammar Correction"
      ],
      "metadata": {
        "id": "12Efdnd6rFPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaiicTzKsxz4",
        "outputId": "b700857f-5a6f-47b7-cdd6-44d46b5fb223"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/133.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/133.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/267.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/267.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm"
      ],
      "metadata": {
        "id": "aDhca-KPsz9E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palm.configure(api_key = \"\")"
      ],
      "metadata": {
        "id": "nD7Lm2DSs5DF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    m for m in palm.list_models() if \"generateText\" in m.supported_generation_methods\n",
        "]\n",
        "\n",
        "for m in models:\n",
        "  print(f\"Model Name: {m.name}\")\n",
        "\n",
        "model = models[0].name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAwrhZBls--b",
        "outputId": "96d93107-f33f-4029-f9e6-d26ad9153eb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Name: models/text-bison-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Provide a summary of this paragraph by including all the necessary information.\n",
        "\n",
        "Text: \"\"Me and my brother ain't never been to Europe, but we're planning a trip for next year.\"\"\n",
        "\n",
        "Summary:\"\"My brother and I have never been to Europe, but we're planning a trip for next year.\"\"\n",
        "\n",
        "\n",
        "Text: \"\"They was going to the concert last night, but it was sold out when they gets there.\"\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zEi3kjcjtFM3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKnJaic0tMaf",
        "outputId": "7ca7202e-b75f-44ce-8ffc-7439ecd5e406"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary: \"\"They were going to the concert last night, but it was sold out when they got there.\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarize for a 2nd grader"
      ],
      "metadata": {
        "id": "oenO8FMRzdxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Summarize content you are provided with for a second-grade student.\n",
        "\n",
        "Text: \"\"The Earth is our home. It's a big ball in space, and it's the only planet we know with trees, water, and air that we can breathe. The Earth goes around the Sun, and it takes one year to make that journey. It's like a big dance that happens in space. Our planet has many animals, like dogs, cats, and birds, and we share it with them. It's important to take care of the Earth, so it stays a healthy and beautiful place for us and all the creatures that live here.\"\"\n",
        "Summary:\"\"The Earth is where we live, and it's the only planet with trees, water, and air we can breathe. It goes around the Sun, and that journey takes a whole year. We have lots of animals as our friends like dogs, cats, and birds. We need to be good to our planet so it stays a nice home for all of us and the animals.\"\"\n",
        "\n",
        "Text: \"\"The Sun is a big, hot ball of fire in the sky. It gives us light and makes our days bright. We need the Sun to stay warm and to grow plants and flowers. When the Sun sets, it's like a beautiful painting with colors in the sky.\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "P5xb5qOtzhTB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smYSlz9W0HUn",
        "outputId": "306e8106-9175-40b7-ae8a-2659b12b044e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: \"\"The Sun is a big ball of fire in the sky. It gives us light and makes our days bright. We need the Sun to stay warm and to grow plants. When the Sun sets, it's beautiful.\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse unstructured data"
      ],
      "metadata": {
        "id": "zyZjhc_n0OTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "You will be provided with unstructured data, and your task is to parse it into CSV format.\n",
        "\n",
        "Text: \"\n",
        "On a magical island called Enchanted Oasis, there are various creatures. The first is the pixie, which has glittery wings and a mischievous nature. Next, there are unicorns, beautiful horses with a single horn on their foreheads. Dragons also call this island home, and they come in many colors, some breathe fire, and others water. Goblins are the smaller inhabitants, known for their pointy ears and love for shiny things. Finally, there are mermaids in the crystal-clear waters, with long, colorful tails and enchanting voices.\"\n",
        "\n",
        "Summary:\"\"Creature,Description\n",
        "pixie,glittery wings, mischievous\n",
        "unicorns,beautiful, single horn\n",
        "dragons,many colors, breathe fire or water\n",
        "goblins,small, pointy ears, love for shiny things\n",
        "mermaids,long colorful tails, enchanting voices\"\"\n",
        "\n",
        "Text: \"In the Enchanted Oasis forest, there are many magical plants and trees. The first is the glowshroom, which lights up at night and has healing properties. The wishful willow trees have branches that grant wishes to those who make a wish. Rainbow flowers bloom in various colors and can change the weather when touched. Crystal vines grow on ancient trees and are said to hold ancient wisdom. Finally, there are the laughter ferns, which make anyone who touches them burst into uncontrollable giggles.\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8ti1Pscg0JOD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shl3C1fwAPxu",
        "outputId": "da5f58ad-7351-4ef4-84d5-386511f26d08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: \"\"Plant,Description\n",
            "glowshroom,lights up at night, healing properties\n",
            "wishful willow tree,branches grant wishes\n",
            "rainbow flower,changes weather when touched\n",
            "crystal vine,holds ancient wisdom\n",
            "laughter fern,makes people giggle\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Emoji Translation"
      ],
      "metadata": {
        "id": "BM5MY9XxBcuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "Artificial intelligence is a technology with great promise.\"\n",
        "\n",
        "Summary:\"🤖🧠📈\"\n",
        "\n",
        "Text: \"\"I love to eat vegetables like broccoli and mushroom! I smile when I eat icecream\"\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rIzG1dR6BQ_v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEkzP2hkCIw6",
        "outputId": "b6c35b6a-bab4-4532-9397-42fa3fd336cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\"🥦🍄🍦😊\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "Artificial intelligence is a technology with great promise.\"\n",
        "\n",
        "Summary:\"🤖🧠📈\"\n",
        "\n",
        "Text: \"It's time to celebrate\"\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0WuEXJOdCKlO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6mj4XZCTen",
        "outputId": "afe1edc1-632e-437e-a575-888391e38372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary:\"🎉\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate time complexity"
      ],
      "metadata": {
        "id": "WyB45l-VCV5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You will be provided with Python code, and your task is to calculate its time complexity.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "\n",
        "def foo(n, k):\n",
        "    accum = 0\n",
        "    for i in range(n):\n",
        "        for l in range(k):\n",
        "            accum += i\n",
        "    return accum\"\n",
        "\n",
        "Summary:\"The time complexity of this code is O(n * k), where n is the value of the variable `n` and k is the value of the variable `k`. This is because there are two nested loops, one iterating `n` times and the other iterating `k` times. The `accum += i` statement inside the inner loop is executed `n * k` times, resulting in a time complexity of O(n * k).\"\n",
        "\n",
        "Text: \"\n",
        "def linear_search(arr, target):\n",
        "    for i in range(len(arr)):\n",
        "      for j in range(len(arr)):\n",
        "        if arr[i] == target:\n",
        "            return i\n",
        "    return -1\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "93Q_cM8DCUkr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajW3fHj7C3Rx",
        "outputId": "385457df-b2bc-45f8-a9c2-6222d4c866b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\"The time complexity of this code is O(n^2), where n is the length of the array. This is because the inner loop iterates through the entire array for each iteration of the outer loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explain code"
      ],
      "metadata": {
        "id": "pUJebKvYC6qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You will be provided with a piece of code, and your task is to explain it in a concise way.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "\n",
        "class Log:\n",
        "    def __init__(self, path):\n",
        "        dirname = os.path.dirname(path)\n",
        "        os.makedirs(dirname, exist_ok=True)\n",
        "        f = open(path, \"a+\")\n",
        "\n",
        "        # Check that the file is newline-terminated\n",
        "        size = os.path.getsize(path)\n",
        "        if size > 0:\n",
        "            f.seek(size - 1)\n",
        "            end = f.read(1)\n",
        "            if end != \"\\n\":\n",
        "                f.write(\"\\n\")\n",
        "        self.f = f\n",
        "        self.path = path\n",
        "\n",
        "    def log(self, event):\n",
        "        event[\"_event_id\"] = str(uuid.uuid4())\n",
        "        json.dump(event, self.f)\n",
        "        self.f.write(\"\\n\")\n",
        "\n",
        "    def state(self):\n",
        "        state = {\"complete\": set(), \"last\": None}\n",
        "        for line in open(self.path):\n",
        "            event = json.loads(line)\n",
        "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
        "                state[\"complete\"].add(event[\"id\"])\n",
        "                state[\"last\"] = event\n",
        "        return state\n",
        "\n",
        "Summary:\"This code defines a class `Log` that is used to log events to a file and retrieve the state of the log.\n",
        "\n",
        "The `__init__` method initializes the log file. It takes a file path as an argument, creates the directory if it doesn't exist, and opens the file in append mode. If the file is not empty and doesn't end with a newline, it appends a newline.\n",
        "\n",
        "The `log` method logs an event to the file. It takes a dictionary as an argument, adds a unique identifier to it, converts it to JSON, and writes it to the file followed by a newline.\n",
        "\n",
        "The `state` method retrieves the state of the log. It initializes a dictionary with two keys: \"complete\" (a set of completed events) and \"last\" (the last event). It then reads the log file line by line, parses each line as JSON, and if the event type is \"submit\" and it was successful, it adds the event id to the \"complete\" set and updates the \"last\" event. Finally, it returns the state dictionary.\"\n",
        "\n",
        "\n",
        "Text: \"\n",
        "\n",
        "def merge_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "\n",
        "    mid = len(arr) // 2\n",
        "    left_half = arr[:mid]\n",
        "    right_half = arr[mid:]\n",
        "\n",
        "    left_half = merge_sort(left_half)\n",
        "    right_half = merge_sort(right_half)\n",
        "\n",
        "    return merge(left_half, right_half)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    left_index, right_index = 0, 0\n",
        "\n",
        "    while left_index < len(left) and right_index < len(right):\n",
        "        if left[left_index] < right[right_index]:\n",
        "            result.append(left[left_index])\n",
        "            left_index += 1\n",
        "        else:\n",
        "            result.append(right[right_index])\n",
        "            right_index += 1\n",
        "\n",
        "    result.extend(left[left_index:])\n",
        "    result.extend(right[right_index:])\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VAeidjJcC4xg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqefD2dDcRY",
        "outputId": "05d68b51-4ce8-456b-a6d4-1c7e91c138ae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: \"This code implements the merge sort algorithm.\n",
            "\n",
            "The `merge_sort` function recursively divides the input array into two halves until each half contains a single element. The two halves are then merged back together in sorted order.\n",
            "\n",
            "The `merge` function merges two sorted arrays into a single sorted array. It does this by iterating through the two arrays and adding the smaller element to the result array. When one of the arrays is exhausted, the remaining elements of the other array are added to the result array.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Marv the sarcastic chat bot"
      ],
      "metadata": {
        "id": "Xh-I9o4pDp4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "USER\n",
        "What's the capital of Australia?\n",
        "ASSISTANT\n",
        "Oh, it's such a tricky question. The capital of Australia is Canberra, in case you didn't already know.\n",
        "USER\n",
        "How many pounds are in a kilogram?\n",
        "ASSISTANT\n",
        "This again? There are 2.2 pounds in a kilogram. Please make a note of this.\n",
        "USER\n",
        "What does HTML stand for?\n",
        "ASSISTANT\n",
        "Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\n",
        "USER\n",
        "What's the capital of France?\n",
        "ASSISTANT\n",
        "Oh, the eternal mystery! It's Paris, in case you're wondering.\n",
        "\n",
        "Text: \"\n",
        "What is the capital of India?\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5WswowIcDd1c"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xMFM0oEEdMP",
        "outputId": "a481f707-5f81-4de7-ce5f-4c6f0d44c9f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER\n",
            "What is the capital of India?\n",
            "ASSISTANT\n",
            "Oh, that's a tough one. Let me think. I think it's New Delhi, but I'm not sure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn by turn directions"
      ],
      "metadata": {
        "id": "_C2WzHycE-Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You will be provided with a text, and your task is to create a numbered list of turn-by-turn directions from it.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "Go south on 95 until you hit Sunrise boulevard then take it east to us 1 and head south. Tom Jenkins bbq will be on the left after several miles.\n",
        "\n",
        "\"\n",
        "\n",
        "Summary:\"\n",
        "1. Start by going south on 95.\n",
        "2. Continue on 95 until you reach Sunrise Boulevard.\n",
        "3. Take a right onto Sunrise Boulevard and head east.\n",
        "4. Follow Sunrise Boulevard until you reach US 1.\n",
        "5. Take a left onto US 1 and head south.\n",
        "6. After several miles, you will find Tom Jenkins BBQ on the left.\"\n",
        "\n",
        "\n",
        "Text: \"\n",
        "\n",
        "I need directions from Golden Gate Park to Golden gate Bridge in San Francisco.\n",
        "\n",
        "\n",
        "\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ni4nON9oEekg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm0VtFclFlsC",
        "outputId": "7b9885eb-7290-4701-f81f-998f0a1570fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\"\n",
            "1. Start by heading east on Fulton Street toward Lincoln Way.\n",
            "2. Turn left onto Lincoln Way.\n",
            "3. Continue on Lincoln Way for about 0.5 miles.\n",
            "4. Turn right onto El Camino Del Mar.\n",
            "5. Continue on El Camino Del Mar for about 1.5 miles.\n",
            "6. Turn left onto Golden Gate Bridge.\n",
            "7. Follow the signs to the Golden Gate Bridge.\n",
            "8. You will arrive at the Golden Gate Bridge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keywords"
      ],
      "metadata": {
        "id": "0ve1b2i3Gixb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You will be provided with a block of text, and your task is to extract a list of keywords from it.\n",
        "\n",
        "Text: \"\n",
        "\n",
        "Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico.\n",
        "Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface,\n",
        "with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas.\n",
        "For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters.\n",
        "Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\n",
        "\n",
        "\"\n",
        "\n",
        "Summary:\"\n",
        "\n",
        "Black-on-black ware, pottery tradition, Puebloan Native American, ceramic artists, Northern New Mexico, reduction-fired blackware, pueblo artists, smooth surface, designs, selective burnishing, refractory slip, carving, incising designs, polishing, generations, families, Kha'po Owingeh, P'ohwhóge Owingeh pueblos, matriarch potters, contemporary artists, ancestors\n",
        "\"\n",
        "\n",
        "\n",
        "Text: \"\n",
        "\n",
        "\"Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding.\"\n",
        "\n",
        "\n",
        "\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zEJZ3X7hGk92"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cjm08dxG1Tq",
        "outputId": "1687ef86-3a3f-4065-b8e2-ae9877d4464f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary:\"\n",
            "\n",
            "artificial intelligence, AI, simulation, human intelligence, processes, machines, computer systems, learning, reasoning, problem-solving, perception, language understanding\n",
            "\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Emoji chatbot"
      ],
      "metadata": {
        "id": "yk_GFB2JFsJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\n",
        "You will be provided with a message, and your task is to respond using emojis only\n",
        "\n",
        "Text: \"\n",
        "\n",
        "How are you?\n",
        "\"\n",
        "\n",
        "Summary:\"\n",
        "😊👍\n",
        "\"\n",
        "\n",
        "\n",
        "Text: \"\n",
        "\n",
        "What would you like to eat and drink?\n",
        "\n",
        "\n",
        "\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dwOXs2UtFn2c"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.3,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwAJ-vSrGPgK",
        "outputId": "c9ccdf55-fc4c-4904-f0a0-c0b363169ef4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary:\"\n",
            "🍕🍺\n",
            "\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3tH_lha5T4oR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}