{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTknd5EWcELhvHXpG6nlWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanasree-Rajamani/SpecialTopics_DeepLearning/blob/main/Assignment%204/part_f_system_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaQ5bv_t0X4U",
        "outputId": "700a9ba5-aa4c-451c-f611-e82969f0ff9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A system prompt is a special message used to steer the behavior of an OpenAI language model. It is a way to provide the model with instructions on what we expect it to do.\n",
        "\n",
        "System prompts can be used to specify the following:\n",
        "\n",
        "The task that the model is expected to perform\n",
        "The tone and style of the response\n",
        "The format of the response\n",
        "Any other constraints on the response\n",
        "System prompts are especially useful for fine-tuning OpenAI models to perform specific tasks. For example, you could use a system prompt to tell the model to generate creative text formats, translate languages, or answer questions about a specific topic."
      ],
      "metadata": {
        "id": "yEIDne_n00ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will generate the following response:\n",
        "\n",
        "The cerebral cortex is the outermost layer of the brain and is responsible for higher-order cognitive functions such as thinking, language, and consciousness. The cerebellum is a smaller structure located at the back of the brain and is responsible for coordinating movement and balance.\n",
        "\n",
        "You can modify the system prompt to specify different use cases for the OpenAI model. For example, you could change the system prompt to:\n",
        "\n",
        "You are a large language model trained to generate creative text formats of text content, like poems, code, scripts, musical pieces, email, letters, etc. Your goal is to fulfill all my requirements.\n",
        "\n",
        "Then, you could use the same Python code to generate different creative text formats of text content, such as a poem about the brain, a code snippet for simulating a neural network, or a script for a play about a neuroscientist."
      ],
      "metadata": {
        "id": "QDSiwMOc0ZkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xOm8bgB0Egn",
        "outputId": "a3465411-3d76-4d2d-a4e1-6f377845ba6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your main application:\n",
            "\n",
            "*Real short-term memory/working memory\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI API client\n",
        "openai.api_key = \"sk-\"\n",
        "\n",
        "import openai\n",
        "\n",
        "# Set the system prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a large language model trained to answer questions about the human brain. Your goal is to provide informative and comprehensive answers, even to challenging or open-ended questions. You should also be able to generate different creative text formats of text content, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to follow your instructions and complete your requests thoughtfully.\n",
        "\"\"\"\n",
        "\n",
        "# Generate text using the system prompt\n",
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=system_prompt,\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example of a system prompt:\n",
        "\n",
        "System prompt:\n",
        "You are a large language model trained to answer questions about the human brain. Your goal is to provide informative and comprehensive answers, even to challenging or open-ended questions. You should also be able to generate different creative text formats of text content, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to follow your instructions and complete your requests thoughtfully.\n",
        "\n",
        "This system prompt tells the model that it is expected to answer questions about the human brain in a comprehensive and informative way. It also tells the model that it should be able to generate different creative text formats of text content.\n",
        "\n",
        "System prompts can be used to improve the performance of OpenAI models in a variety of ways. For example, system prompts can be used to:\n",
        "\n",
        "Reduce the amount of training data required to fine-tune a model for a specific task\n",
        "Improve the accuracy and fluency of translations\n",
        "Generate more creative and engaging text content\n",
        "Make the model more responsive to user instructions\n",
        "If you are using OpenAI models to perform specific tasks, I recommend using system prompts to fine-tune the models for those tasks. System prompts can help you to get the most out of OpenAI models and improve the performance of your applications."
      ],
      "metadata": {
        "id": "rPumENhj08D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the system prompt \"You are a virtual assistant designed to help users with common tasks. Please assist the user with their request.\" sets the context for the assistant to understand that it should behave as a virtual assistant. The user's message \"Find me a recipe for homemade pizza.\" is processed within this context, and the assistant generates a response accordingly.\n",
        "\n",
        "System prompts are particularly useful for guiding the behavior of the model, especially in chat-based applications, where the role and context of the assistant need to be clearly defined. The system prompt provides a high-level instruction to the model, which helps it understand the context of the conversation and generate appropriate responses."
      ],
      "metadata": {
        "id": "-hztqBWT3rPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "api_key = \"sk-\"\n",
        "\n",
        "# Define the system prompt to set the context\n",
        "system_prompt = \"You are a virtual assistant designed to help users with common tasks. Please assist the user with their request.\"\n",
        "\n",
        "# User's message\n",
        "user_message = \"Find me a recipe for homemade pizza.\"\n",
        "\n",
        "# Generate a response using the system prompt and user message\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ],\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Extract the model's response\n",
        "assistant_response = response.choices[0].message[\"content\"]\n",
        "\n",
        "# Print the response\n",
        "print(\"User:\", user_message)\n",
        "print(\"Assistant:\", assistant_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9R9eIpi25d2",
        "outputId": "8bfe879e-a6a3-4373-9a35-691aa4a4582e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Find me a recipe for homemade pizza.\n",
            "Assistant: Certainly! Here's a recipe for homemade pizza:\n",
            "\n",
            "Ingredients:\n",
            "- 2 ¼ teaspoons (1 packet) active dry yeast\n",
            "- 1 teaspoon sugar\n",
            "- 1 ¼ cups warm water\n",
            "- 3 ¼ cups all-purpose flour\n",
            "- 2 teaspoons salt\n",
            "- 2 tablespoons olive oil\n",
            "- Pizza sauce\n",
            "- Mozzarella cheese\n",
            "- Toppings of your choice (e.g., pepperoni, bell peppers, mushrooms)\n",
            "\n",
            "Instructions:\n",
            "1. In a small bowl, combine the yeast, sugar, and warm water. Stir gently and let it sit for about 5 minutes until the mixture becomes foamy.\n",
            "\n",
            "2. In a large mixing bowl, combine the flour and salt. Add the yeast mixture and olive oil, then mix until a sticky dough forms.\n",
            "\n",
            "3. Transfer the dough to a floured surface and knead for about 5 minutes until smooth and elastic. If the dough feels too sticky, add a little more flour.\n",
            "\n",
            "4. Place the dough in a greased bowl, cover it with a clean kitchen towel, and let it rise in a warm area for about 1 hour or until doubled in size.\n",
            "\n",
            "5. Preheat your oven to 475°F (245°C) and place a pizza stone or baking sheet in the oven to preheat as well.\n",
            "\n",
            "6. On a lightly floured surface, divide the dough in half (or into desired portions for personal-sized pizzas). Roll out each portion into a round or rectangular shape, about ¼-inch thick.\n",
            "\n",
            "7. Transfer the rolled-out dough onto a piece of parchment paper. This will make it easier to transfer the pizza onto the preheated pizza stone or baking sheet later.\n",
            "\n",
            "8. Spread a thin layer of pizza sauce onto the dough, leaving a small border around the edges. Add your desired amount of cheese and toppings.\n",
            "\n",
            "9. Carefully transfer the pizza (with the parchment paper) onto the preheated pizza stone or baking sheet in the oven.\n",
            "\n",
            "10. Bake for about 12-15 minutes or until the crust is golden and the cheese is melted and bubbly.\n",
            "\n",
            "11. Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.\n",
            "\n",
            "Enjoy your homemade pizza!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsmCwnx026rH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}