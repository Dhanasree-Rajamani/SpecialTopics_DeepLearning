Question 2: Transformers and finetuning with LLMs

a) Implement nanogpt from scratch using your own code in pytorch, tensorflow and jax

Text generation with NanoGPT using Pytorch: 

https://drive.google.com/file/d/15KOzGX08XStRZyZIBwm1IBB6d08fgqKK/view?usp=sharing

Text generation with NanoGPT using Tensorflow: 

https://colab.research.google.com/drive/1eBa4mY_RJXG4XYd1zPErXg-Cn677K0Hq?usp=sharing

Text generation with NanoGPT using JAX: 

https://colab.research.google.com/drive/1krZKZE0dwNcCCWgoaB7X2Hug4ZNOFHMx?usp=sharing

Medium Article: https://medium.com/@dhanasree.rajamani/text-generation-with-transformers-98fdd86f81aa

b) Implement "textbooks are all you need"

Use the existing model that is finetuned with python dataset, as well as generated a dataset with mental health related text, to finetune the model. This is used to build a chatbot which can guide user with their mental health. 

Colab: https://colab.research.google.com/drive/1rrhMVkVc_0TjeIUBMq7vVb-ONa1gHVI1?usp=sharing
